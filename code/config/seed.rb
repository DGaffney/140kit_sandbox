Setting.create(:name => 'user_role_tweet_limit', :var_type => 'Admin', :var_class => 'integer', :value => 20000000)
Setting.create(:name => 'user_role_tweet_limit', :var_type => 'User', :var_class => 'integer', :value => 20000)
Setting.create(:name => 'user_role_tweet_limit', :var_type => 'Academic', :var_class => 'integer', :value => 500000)
Setting.create(:name => 'user_role_tweet_limit', :var_type => 'Commercial Account', :var_class => 'integer', :value => 200000)
Setting.create(:name => 'user_role_tweet_limit', :var_type => 'Inactive', :var_class => 'integer', :value => 0)
Setting.create(:name => 'user_role_tweet_limit', :var_type => 'Suspended', :var_class => 'integer', :value => 0)
Setting.create(:name => 'max_track_ids', :var_type => 'Filter Setting', :var_class => 'integer', :value => 10000)
Setting.create(:name => 'batch_size', :var_type => 'Filter Setting', :var_class => 'integer', :value => 100)
Setting.create(:name => 'check_for_new_datasets_interval', :var_type => 'Filter Setting', :var_class => 'integer', :value => 30)
Setting.create(:name => 'rsync_interval', :var_type => 'Filter Setting', :var_class => 'integer', :value => 1800)
Setting.create(:name => 'statuses', :var_type => 'Dataset Settings', :var_class => 'array', :value => ["tsv_storing", "tsv_stored", "needs_import", "imported", "live", "needs_drop", "dropped", "zero_data", "hidden"])
Setting.create(:name => 'unflippable_statuses', :var_type => 'Dataset Settings', :var_class => 'array', :value => ["zero_data", "imported", "tsv_stored", "dropped", "hidden"])
Setting.create(:name => 'sleep_constant', :var_type => 'Instance Settings', :var_class => 'integer', :value => 30)
Setting.create(:name => 'drop_interval', :var_type => 'Worker Setting', :var_class => 'integer', :value => 86400)
Setting.create(:name => 'hide_interval', :var_type => 'Worker Setting', :var_class => 'integer', :value => 2419200)
Setting.create(:name => 'clean_orphan_interval', :var_type => 'Worker Setting', :var_class => 'integer', :value => 900)
Setting.create(:name => 'roles', :var_type => 'User Roles', :var_class => 'array', :value => ["Inactive", "Suspended", "User", "Academic", "Admin"])
Setting.create(:name => 'maximum_user_search', :var_type => 'User', :var_class => 'integer', :value => 10)
Setting.create(:name => 'maximum_user_search', :var_type => 'Academic', :var_class => 'integer', :value => 100)
Setting.create(:name => 'maximum_user_search', :var_type => 'Admin', :var_class => 'integer', :value => 1000)
advanced_histogram = AnalyticalOffering.create(:title => "Advanced Histograms!", :description => "Advanced Histograms", :function => "advanced_histogram", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/advanced_histogram.rb")
basic_histogram = AnalyticalOffering.create(:title => "Basic Histograms", :description => "Create basic histograms for all quantifiable attributes for users and tweets in the data set. Example: All users have follower counts (the number of people following them); this matches the number of followers to the number of users that have that many followers. With tweet's created_at time stamp, the number tweets created at every time step is created in a simple graph format. This data is then available in the collection view of your data set; you can then consume this information as google charts (with embed code included) data, JSON, CSV, or XML.", :function => "basic_histogram", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/basic_histogram.rb")
interaction_list = AnalyticalOffering.create(:title => "Interaction List", :description => "Generates all edges of types mention, retweet, and friendship", :function => "interaction_list", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/edge_generator.rb")
gender_estimation = AnalyticalOffering.create(:title => "Gender Estimation", :description => "This Analytic pings the TrueKnowledge.com database to find out if a user's name (not their Username, but the name that they put in as their actual name) is either typically Male or Female. If it cannot conclusively attach a gender to the name, it reports the name as Inconclusive. In short, if it DOES select a name, it is very likely that the gender guess is accurate.", :function => "gender_estimation", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/gender_estimation.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "sample_size", :description => "Select 'retweet' to generate a network map solely consisting of retweets; select 'mention' to generate a network map of 'mentions'; select 'combined' to mix both together", :user_modifiable => true, :position => 1, :kind => "integer", :analytical_offering_id => gender_estimation.id, :values => nil)
mysql_dumper = AnalyticalOffering.create(:title => "MYSQL Dumper", :description => "Dump all the data from your collection into .sql files, which are then available on our file system on the server for ever and ever. It's always a bad idea to have no back-ups of data; it's even worse to not have redundant data. This allows you to create your own MySQL database with all your tweets and users intact (and mapped to one another with our indices) without losing a beat so that you can do whatever you will with the data separately and off of our site in case we don't have the analytics you want.", :function => "mysql_dumper", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/mysql_dumper.rb")
network_grapher = AnalyticalOffering.create(:title => "Network Grapher", :description => "Generates network graphs in gexf and graphml of either mentions/retweets, friendships, or both.", :function => "network_grapher", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/network_grapher.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "graph_type", :description => "Select 'retweet' to generate a network map solely consisting of retweets; select 'mention' to generate a network map of 'mentions'; select 'combined' to mix both together", :user_modifiable => true, :position => 1, :kind => "string", :analytical_offering_id => network_grapher.id, :values => nil)
raw_csv = AnalyticalOffering.create(:title => "Raw CSV", :description => "Dump all the data from your collection into .csv files, which are then available on our file system on the server for ever and ever. With CSV, you can easily open up the data in Excel, OpenOffice (god bless you), or something similar, or just push it into some other data base solution as this is one of the most simple forms of transitioning data from one place to another. Allows for simple access to the data without much thought put into it, and gets you rolling on your own research.", :function => "raw_csv", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/raw_csv.rb")
time_based_summary = AnalyticalOffering.create(:title => "Time Based Summary", :description => "Break your histograms (and resultant CSVs) into smaller pockets of time - want to see the specific traffic for one hour's worth of data? You sould look at it by navigating to the Year/Month/Day/Hour location of the folder structure resulting from a Time-Based summary, and be able to look at all the basic histograms usually available.", :function => "time_based_summary", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/time_based_summary.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "granularity", :description => "Select 'retweet' to generate a network map solely consisting of retweets; select 'mention' to generate a network map of 'mentions'; select 'combined' to mix both together", :user_modifiable => true, :position => 1, :kind => "string", :analytical_offering_id => time_based_summary.id, :values => nil)
word_frequency = AnalyticalOffering.create(:title => "Word Frequencies", :description => "The Word Frequency Analytic reads through your collection of tweets and keeps track of the number of occurrences of each word. From there, it breaks this 'Word Frequency hash' into four distinct categories: Hashtags, Mentions, Non-Stop Words (excluding words like 'it', 'the', 'he', 'she', etc..), and Links. It then pushes charts of the frequencies of occurrence into a Google Charts table so you can easily go through the results - raw CSVs of this data are also available. In other words, when you include this Analytic, you are able to quickly see the most often-used Hashtags, Links, Usernames, and Words in order to quickly get a high-level overview of the data", :function => "word_frequency", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/word_frequency.rb")
basic_user_statistic = AnalyticalOffering.create(:title => "Basic User Statistics", :description => "blah", :function => "basic_user_statistic", :rest => false, :created_by => "140kit Team", :created_by_link => "http://www.140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/basic_user_statistics.rb")
gender_estimation = AnalyticalOffering.create(:title => "Gender Estimation", :description => "This function leverages the TrueKnowledge database to determine if the user's provided screen name is likely to be a male or female. If it cannot determine the value, it assigns an \"unknown\" value to the user.", :function => "gender_estimation", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => false, :language => "ruby", :access_level => "User", :source_code_link => "https://github.com/DGaffney/140kit_sandbox/blob/master/code/analyzer/tools/gender_estimation.rb")
compact_language_detection = AnalyticalOffering.create(:title => "Compact Language Detection", :description => "Generally, Twitter's language score is alright - over the past few years, their integration of language detection algorithms, at least on the outside, seem to cover somewhere around 30 languages, and performs relatively well. This analytic, however, supercharges this process. Compact Language Detection, or CLD, is a port of the Google Chrome browser language detection algorithm, which includes 100+ languages and is super, super good.", :function => "compact_language_detection", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "https://github.com/DGaffney/140kit_sandbox/blob/master/code/analyzer/tools/compact_language_detection.rb")
entity_extractor = AnalyticalOffering.create(:title => "Entity Extractor", :description => "This function extracts and tabulates the entities used across the entire dataset. In Twitter parlance, an entity is an occurrence of a screen name (called a mention), hashtag, or URL within the text of a tweet. Multiple entities can be mixed and matched within any given Tweet. By looking at the top users, you can get a sense of influential users; by looking at hashtags, you can start to draw out a qualitative sense of the streams contents; by looking at the URLs, you can start to draw out the connection the group of users have to the rest of the internet.", :function => "entity_extractor", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "https://github.com/DGaffney/140kit_sandbox/blob/master/code/analyzer/tools/entity_extractor.rb")
conversational_network_graph = AnalyticalOffering.create(:title => "Conversational Network Graph", :description => "Conversational Network Graph!", :function => "conversational_network_graph", :rest => false, :created_by => "140kit Team", :created_by_link => "http://www.140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/conversational_network_graph.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "network_type", :description => "Select 'retweet' to generate a network map solely consisting of retweets; select 'mention' to generate a network map of 'mentions'; select 'combined' to mix both together", :user_modifiable => true, :position => 0, :kind => "enum", :analytical_offering_id => conversational_network_graph.id, :values => "retweet,mention,combined")
AnalyticalOfferingRequirement.create(:position => 0, :analytical_offering_requirement_id => 3, :analytical_offering_id => 14)
geo_map = AnalyticalOffering.create(:title => "Geo Map", :description => "Takes all Geotagged tweets from this dataset and plots them on a map at both the country and city levels - also provides a summary of exactly how many tweets were geotagged.", :function => "geo_map", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/geo_map.rb")
word_frequency = AnalyticalOffering.create(:title => "Word Frequencies", :description => "So you know how many hashtags, mentions and links occurred and what they were - what about normal words, though? This analytic provides you with a comprehensive counting of every word that occurred. This function has one variable, percentile, which is the cutoff limit for words to appear - the default is 0.9, or only show the top 10% used words. This should be set relatively high as word distributions get very large and the long tail is looooong, and you won't ever use it. Promise.", :function => "word_frequency", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/word_frequency.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "Percentile", :description => "The percentile at which the word frequency algorithm cuts off results. The value, represented in decimal notation, corresponds to the portion of results that are omitted. A value of 0.9, for instance, is the 90th percentile, which means that only the top 10% occurring words will be shown in the results. No stop words are removed so as to make this an entirely transparent analytic.", :user_modifiable => true, :position => 0, :kind => "enum", :analytical_offering_id => word_frequency.id, :values => "0.99,0.95,0.9,0.85,0.80,0.75,0.7,0.6,0.5,0.4,0.3,0")
audience_report = AnalyticalOffering.create(:title => "Audience Report", :description => "This analytic will provide you a set of information about the impressions made over time for the dataset. Impressions are calculated by the sum of follower counts for users who tweeted within a given time frame. Practically speaking, when a user with a follower count of 100 users tweets, those 100 users will have that user's tweet appear in their feed. When taken together, you can quickly get a sense of how many other people directly had access to a posted message. This is only an approximate value, however - it provides an inflated measure because there may be many mutually following users (User A tweets and User B tweets, each have 100 followers - if any people follow both A and B, the sum of the impressions should check against the union of the follower lists, instead it does not do this due to the excessive API calls involved). Additionally, even though a tweet can be fed to someone's feed, it doesn't really get \"impressed\" unless the person actually logs in and sees it. In talking about this data, then, it would behoove you to describe this value as the maximum number of people who could have seen the content that was posted at the time that it was posted. ", :function => "audience_report", :rest => false, :created_by => "140kit Team", :created_by_link => "http://140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "https://github.com/DGaffney/140kit_sandbox/blob/master/code/analyzer/tools/audience_report.rb")
semantic_analyzer = AnalyticalOffering.create(:title => "Semantic Analyzer", :description => "This Analytic provides a semantic matching score for words in the dataset either by using Latent Semantic Analysis (LSA) or Term Frequency/In-document frequency (TFIDF) methods. The results provided are pruned by a given percentile of matches - a percentile of 0.99 corresponds to a returned set of only the highest 1% of semantically useful terms across the dataset. In practice, what this provides you is the other closely matching terms that the dataset matches - for example, if you searched for \"Romney\", \"Mitt\" should appear high up on the list, alongside possibly surprising terms, which is what you can use to gain a sense of the types of topics that these tweets cover.", :function => "semantic_analyzer", :rest => false, :created_by => "140kit Team", :created_by_link => "http://www.140kit.com", :enabled => true, :language => "ruby", :access_level => "Admin", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/semantic_analyzer.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "percentile", :description => "The percentile at which the semantic analyzer algorithm cuts off results. The value, represented in decimal notation, corresponds to the portion of results that are omitted. A value of 0.9, for instance, is the 90th percentile, which means that only the top 10% semantically matched words will be shown in the results. No stop words are removed so as to make this an entirely transparent analytic.", :user_modifiable => true, :position => 0, :kind => "enum", :analytical_offering_id => semantic_analyzer.id, :values => "0.99,0.95,0.9,0.85,0.80,0.75,0.7,0.6,0.5,0.4,0.3,0")
AnalyticalOfferingVariableDescriptor.create(:name => "analysis_type", :description => "Choose either  Latent Semantic Analysis (lsa) or Term Frequency/In-document frequency (tfidf). Both are relatively similar in terms of the results they provide, but have their own nuances. To read up more, please visit the <a href=\"http://en.wikipedia.org/wiki/Latent_semantic_analysis\" target=\"_blank\">LSA</a> and <a href=\"http://en.wikipedia.org/wiki/Tf*idf\" target=\"_blank\">TFIDF</a> pages on Wikipedia.", :user_modifiable => true, :position => 1, :kind => "enum", :analytical_offering_id => semantic_analyzer.id, :values => "tfidf,lsa")
fast_semantic_analyzer = AnalyticalOffering.create(:title => "Fast Semantic Analyzer", :description => "This analytical function only runs TFIDF, but runs much faster than the Semantic Analyzer. The loss here is that this implementation does not level at each stage of analysis, and the numbers are calculated slightly differently, but the results shouldn't differ too much from the more comprehensive analytic. ", :function => "fast_semantic_analyzer", :rest => false, :created_by => "140kit Team", :created_by_link => "http://www.140kit.com", :enabled => true, :language => "ruby", :access_level => "User", :source_code_link => "http://www.github.com/DGaffney/140kit_sandbox/tree/master/code/analyzer/tools/fast_semantic_analyzer.rb")
AnalyticalOfferingVariableDescriptor.create(:name => "percentile", :description => "The percentile at which the semantic analyzer algorithm cuts off results. The value, represented in decimal notation, corresponds to the portion of results that are omitted. A value of 0.9, for instance, is the 90th percentile, which means that only the top 10% semantically matched words will be shown in the results. No stop words are removed so as to make this an entirely transparent analytic.", :user_modifiable => true, :position => 0, :kind => "enum", :analytical_offering_id => fast_semantic_analyzer.id, :values => "0.99,0.95,0.9,0.85,0.80,0.75,0.7,0.6,0.5,0.4,0.3,0")
Post.create(:id => 2, :title => "#StopKony: A tale of good intentions?", :slug => "stop-kony", :text => "This is a good story to understand the basics of why we want to study Twitter. Twitter is a very useful thing to study and is fun to think about. I like to write things. This is fun. Just running down the post size to try to get things going on the new site.", :created_at => Time.parse("2012-03-14 21:34:56 +0000"), :status => "featured", :researcher_id => 1)
Post.create(:id => 3, :title => "About 140kit", :slug => "about", :text => "<h1>Basic Background</h1>\r\n\r\n140kit is a project that has been around in some form or implementation since October 2009. <a href=\"http://ianpearce.info/\">Ian Pearce</a> and <a href=\"http://devingaffney.com\">Devin Gaffney</a>, along with additional help during <a href=\"http://bennington.edu\">Bennington's</a> Spring 2010 term from <a href=\"http://maxnanis.com/\">Max Nanis</a>, <a href=\"http://maxdarham.com/\">Max Darham</a>, and the fine folks at the <a href=\"http://webecologyproject.org/\">Web Ecology Project</a>, have been working on this labor of love for... forever. When Gaffney was working on his senior thesis on the Iran Election and the impact of social media, he realized that the analytical processes, Tweet collection systems, and printouts could be written in a much less tailored way - by adding a management layer on top of it, you could effectively provide a way for researchers to research Twitter. \r\n\r\nBasically, if you're going to research Twitter on your own, you need to make sure you meet the following requirements: \r\n  1. You have a good set of code to analyze with. \r\n  2. This code suffers from no bugs, and consistently returns all the possible data of interest, and  \r\n  3. It's constantly connected to the internet. \r\n\r\nWhile theoretically possible, in practice, this is a high bar. When you don't have these things, you can quickly find yourself left out of researching Twitter, when, in all likelihood, you would be able to come up with very useful results. We decided to create this then in order to enable you to research without worrying about any of these issues. You give us the job, and we take care of it for you, free of charge. \r\n\r\n<h1>The Catch</h1>\r\n\r\nThere is one catch, however - <a href=\"http://www.readwriteweb.com/archives/how_recent_changes_to_twitters_terms_of_service_mi.php\" target=\"_blank\">Twitter doesn't allow us to give you raw data</a>. What we can do, however, is run *any* analytical process you would ever want, and we can hold on to the data for as long as you want. When new analytical processes are created, you can run them on your existing sets of data. We do not claim any control of the analysis - you can use it without worrying about us scooping your research. We do, however, 'own' the data collected. We give you the analytics, but we can't give you the raw data. But who wants to deal with that anyways?\r\n\r\n<h2>Limits</h2>\r\n\r\nWe would love to serve everyone in full all of the time without exception. In practice however, we're a very small outfit. For this reason, until we see we can do it with no problem, we're limiting any given collection of data in the following way. User's have different \"roles\" on the site, meaning they have different access levels. When you sign up for an account, you're a User by default. You have to get in touch with us about changing your status - this can be done by pinging us at <a href=\"http://twitter.com/140kit\" target=\"_blank\">Twitter</a> or <a href=\"mailto:140kit@gmail.com?subject=Upgrade My Account!\">e-mail</a>. This is the current breakdown:\r\n\r\n<ul>\r\n<li><b>If you're a User:</b> 20,000 Tweets per Dataset <em>or</em> until Dataset time elapses</li>\r\n<li><b>If you're an Academic:</b> 500,000 Tweets per Dataset <em>or</em> until Dataset time elapses</li>\r\n</ul>\r\n<em>These are soft settings - it will stop when it gets around those numbers, not exactly those numbers. They will always be above 20,000 or 500,000, however.</em>\r\nWhat this means for you is if you create a dataset that does something like a week long pull of all geocoded tweets, or a week long pull of all tweets that use the word \"lol\", at some point, we really can't collect all of it, and chances are very, very, high that you're not going to want that type of data anyways. If you want random large sets, let us know and we'll incorporate a random constant feed. \r\n\r\nOther than that, game on. Oh, and feel free to tell us how were doing via <a href=\"http://twitter.com/140kit\" target=\"_blank\">Twitter</a> or <a href=\"mailto:140kit@gmail.com\">e-mail</a>.", :created_at => Time.parse("2012-03-26 00:36:07 +0000"), :status => "regular", :researcher_id => 1)
Post.create(:id => 4, :title => "Learn about 140kit", :slug => "learn", :text => "Ok, so in order to make this point I have to introduce you to someone. \r\n\r\nWorld, meet my friend Hugh:\r\n\r\n<div align=\"center\">\r\n<img class=\"img_shadow\" src=\"http://f.cl.ly/items/3E1c0D2U3c0w0T2e0Z1T/Screen%20Shot%202012-03-27%20at%2011.57.02%20PM.png\"/>\r\n</div>\r\n\r\nHe's sleeping. He's also a great guy. And according to <a href=\"http://klout.com\" target=\"_blank\">Klout</a>, he's an expert in vampires. How do I know? Well it popped up in my Facebook feed:\r\n\r\n<div align=\"center\">\r\n<img class=\"img_shadow\" src=\"http://cl.ly/0A2u1C1P0T13462K0t0S/426754_3020185498465_1077488913_32854126_1806630369_n.jpeg\"/>\r\n</div>\r\n\r\nNow, I know Hugh real well, so I have a bit of a lead on you all. But I can bet that your once-over on Hugh suggests that, in fact, he is not an expert in Vampires. He doesn't write Vampire fan fiction, he probably didn't even see the <a href=\"http://en.wikipedia.org/wiki/Twilight_(series)\" target=\"_blank\">Twilight</a> movies (much less the series), and he's probably pretty ambivalent about the whole thing. Why is he an expert? Because he's:\r\n\r\n1. An active Twitter user\r\n2. Tweeted about Vampires once or twice\r\n\r\nThat's about all I can tell you, because Klout's system is proprietary, and I can't point to the exact line of code that decided he was an expert. All I can do is say that the special sauce deemed him to be one. And that's the problem: in our collective effort to distill the utility of social media, we have adopted a reductionist view of the whole thing, where you're defined by a single integer, your Klout score, or you're deemed to be a \"mover and shaker\" because you show up on lots of user lists on Twitter. And then we're left with situations where a single Tweet like this seems to make you an expert:\r\n\r\n<div align=\"center\">\r\n<blockquote class=\"twitter-tweet\"><p>I got you this giant teddy bear wearing a vampire costume</p>&mdash; Hugh (@hughelton) <a href=\"https://twitter.com/hughelton/status/169580813514579968\" data-datetime=\"2012-02-15T00:36:31+00:00\">February 15, 2012</a></blockquote>\r\n<script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\r\n</div>\r\n\r\nSure, you can make these things smart. Maybe there's an algorithm that can do this reliably - maybe we COULD reduce everyone to a single set of digits, and determine who matters in a set of data and who doesn't. Clearly, though, this isn't it. We have a long way to go until we can reduce human social activities into a program. What we see right now is not an effort to understand these systems, its an effort to make money off of feel good pseudo-analysis that you can sell to some higher-up. <a href=\"http://gnip.com/\" target=\"_blank\">And</a> <a href=\"http://www.socialbro.com/\" target=\"_blank\">it</a> <a href=\"http://www.graphedge.com/\" target=\"_blank\">doesn't</a> <a href=\"http://foller.me/\" target=\"_blank\">stop</a> <a href=\"http://omnituretwitteranalytics.com/\" target=\"_blank\">at</a> <a href=\"http://www.klout.com\" target=\"_blank\">Klout</a>. Wait, hold on.\r\n\r\n<div align=\"center\">\r\n<img class=\"img_shadow\" src=\"http://cl.ly/281A3D090y231y143x1z/Screen%20Shot%202012-03-28%20at%2012.28.49%20AM.png\"/>\r\n</div>\r\n\r\nOk, notification noted. Anyways. The point is, the people who run 140kit, <a href=\"http://devingaffney.com\">Devin Gaffney</a> and <a href=\"http://ianpearce.info\">Ian Peace</a> come from an angle where we are humble about the business of understanding social media. We *don't* know the answer to everything, and its very likely we *can't* deliver a simple single metric. When someone says they *can* do it, a major indicator that they *can't* is when they completely obfuscate the system that their numbers come out of. \r\n\r\nInstead, we want to give you freedom to determine what matters. We don't know the answer, but we do know how to build an engine that can help you figure out what matters to you. If you want to know the most influential accounts calculated by the raw number of times they appeared in a data set, we got you. If you want eigenvector centralities from the retweet network, we got you too. If you want to see what stated languages they speak in, great. If you don't trust Twitter's language settings (and you <a href=\"http://www.geospace.co.uk/files/icwsm_paper2.pdf\" target=\"_blank\">shouldn't</a>), we'll give you an analytic that recodes the tweets to the best algorithm we can find. If you don't see the analytical process you want, you can <a href=\"https://github.com/DGaffney/140kit_sandbox\">write one and submit it to us</a>, because 100% of our system is open source (ok, we left out the database passwords, but thats it). If you don't know how to write these things, tell us and we'll write it if we think its important. \r\n\r\nWe don't know the answers to your dataset, because no one knows the answers to your dataset. What we're in the business of doing is giving you the tools, real, transparent, and unforgiving though they may be, to figure out what really matters, if it matters at all.\r\n\r\nGood luck.", :created_at => Time.parse("2012-03-26 00:43:59 +0000"), :status => "regular", :researcher_id => 1)
Post.create(:id => 5, :title => "Policy and Terms of Service Stuff", :slug => "policy", :text => "h2. General License\r\n\r\n<img src=\"http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png\" />\r\n<a href=\"http://140kit.com\">140kit</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>.<br />\r\n\r\nh2. Specifics\r\n\r\nh3. Twitter's data\r\n\r\n140kit collects data using it's own account via Twitter's Streaming API. As such, pursuant to section I 4. a. of <a href=\"https://dev.twitter.com/terms/api-terms\">Twitter's Developer Terms of service</a>, we do not provide syndicated data, and do not \"sell, rent, lease, sublicense, redistribute, or syndicate access to the Twitter API or Twitter Content\" In any sense. What this service aims to do is provide analytical services surrounding Twitter data, which is outlined in Section 2 of the Terms of Service: \"You may use the Twitter API and Twitter Content in connection with the products or services you provide (your \"Service\") to search, display, analyze, retrieve, view, and submit information to or on Twitter.\"\r\n\r\nAs a result of these restraints, we maintain ownership of all data on this website - tweets collected by 140kit are tweets that belong to 140kit. The analytical results are displayed for all users, and are licensed to users under a cc-by-nc-sa license unless specifically stated otherwise, at which point the more specific difference expressed takes precedence. \r\n\r\nh3. Your data\r\n\r\nBy using this service, you provide OAuth access to your Twitter account - though we do store basic user information, including your screen name, url, description, and user name. Beyond this, we do make a request that your e-mail account is provided, as we need a more permanent way to get in contact with you if necessary. These details will *never* be given out to any other party, and we will comply with any requests to remove data you may deem too sensitive. \r\n\r\nh3. Collected data\r\n\r\nIf, somehow, your data has been collected by a streaming dataset on our system, and has created some form of grief for you, we're willing to figure out how to address your concerns. E-mail us at <a href=\"mailto:140kit@gmail.com\">140kit@gmail.com</a> in order to start figuring out what we can do for you. \r\n\r\nh3. If things go south\r\n\r\nIf we find that you are systematically abusing our system, we reserve the right to suspend you're account. Not sure what that means, but just be aware that doing things that make you think - \"huh, this is pretty abusive\" - will probably lead us to think the same thing, and we'll have to do sad things like delete data, which would suck. Probably won't happen, you people seem nice, but, just thought it was worth saying.", :created_at => Time.parse("2012-04-04 16:26:05 +0000"), :status => "hidden", :researcher_id => 1)
  Post.create(:id => 6, :title => "Request Wall", :slug => "request-wall", :text => "If you don't see an analytic that you would want, post it in the thread on this post, and we'll look into it.", :created_at => Time.parse("2012-04-06 04:06:21 +0000"), :status => "regular", :researcher_id => 1)